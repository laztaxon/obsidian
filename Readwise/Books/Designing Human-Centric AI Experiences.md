# Designing Human-Centric AI Experiences

![rw-book-cover](https://m.media-amazon.com/images/I/617jqZeOfAL._SY160.jpg)

## Metadata
- Author: [[Akshay Kore]]
- Full Title: Designing Human-Centric AI Experiences
- Category: #books

## Highlights
- If we want to build a machine that thinks like humans, we need to determine a way of how humans think. These approaches focus on what goes inside the human mind. There are three key ways18 of understanding this: 1. Through introspection by catching our thoughts   2. Through psychological experiments by observing a person in action   3. Through brain imaging by observing the brain in action   This approach focuses on building a sufficiently precise theory of the mind and translating that into a computer program. ([Location 504](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=504))
    - Tags: [[orange]] 
- A syllogism provides a pattern for structuring an argument that always yields the correct result given the context. These structures are supposed to be irrefutable. “Socrates is a man; all men are mortal; therefore, Socrates is mortal” is a famous syllogism. ([Location 513](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=513))
    - Tags: [[orange]] 
- This approach hopes to build intelligent systems on the foundations of logic. However, we run into two critical problems: 1. The logical approach assumes 100% certainty about knowledge of the world. In the real world, informal knowledge is often uncertain and incomplete, and in general, no single person or agent has complete understanding.   2. There are currently limits to computation. There is a big difference between solving a problem in theory and solving it. Even a few hundred parameters, in theory, can exhaust computational resources. The real world has a lot more. ([Location 516](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=516))
    - Tags: [[orange]] 
- Trying to fool humans has led to significant advances in adjacent technologies in AI. The computer needs the following capabilities to act humanly:19 1. Natural language processing to understand and communicate with people   2. Knowledge representation to store and organize what it knows and hears   3. Automated reasoning to use the stored information to answer questions and carry out conversations   4. Machine learning (ML) to find patterns and adapt to changing circumstances   5. Computer vision to perceive objects   6. Robotics to move around and manipulate objects   All of these are hard problems and compose most of modern AI. ([Location 524](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=524))
    - Tags: [[blue]] 
- Rational agents, in many cases, need to act appropriately with limited information or computational resources. This is called “limited rationality,” which is how most real-world AI systems operate. The rational agent approach has two advantages over other approaches:20 1. It is more general than the “thinking rationally” approach because correct inferences are just one way of acting rationally.   2. It is more amenable to scientific development than approaches based on human behavior or thinking. Rationality is mathematically well defined and completely general, and we can unpack it to generate AI designs that achieve goal-oriented behavior. ([Location 544](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=544))
    - Tags: [[blue]] 
- This book adopts the view that intelligence is concerned with acting rationally. An intelligent agent takes the best possible action in a situation despite limited information or resources. We will look at designing AI experiences that are intelligent in this sense. ([Location 551](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=551))
    - Tags: [[pink]] 
- The quality of intelligence has an intangible, ethereal, or abstract feel because it is substrate independent: it can take a life of its own irrespective of the details of the underlying material substrate. ([Location 558](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=558))
- Substrate independence doesn’t mean that a substrate is unnecessary. It means that the details of the underlying substrate are irrelevant. Intelligence can exist in networks of neurons in the brain as well as on silicon-based computers.   2. We are primarily interested in the substrate-independent aspect of intelligence and AI. Although modern AI is closely associated with computer science that works with silicon hardware, if we successfully build AI on biological substrates, we won’t abandon designing AI systems since the underlying substrate does not matter. ([Location 561](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=561))
- Intelligent behavior requires reasoning to justify actions. Parts of philosophy deal with the connection of knowledge and action, that is, reasoning, which is vital to building rational agents since intelligence requires action backed by proper justifications. ([Location 586](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=586))
- Mathematicians provided tools and techniques to manipulate logical, probabilistic, or uncertain statements. Mathematics also sets the foundation for computation and reasoning through algorithms. ([Location 592](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=592))
- In AI, a rational agent needs to make appropriate decisions in uncertain situations. The field has borrowed many ideas from economics involving single or multiple agents in an environment. ([Location 596](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=596))
- Different movements in psychology have tried to understand how humans think and act, and artificial intelligence has used many of its learnings to build important AI components. One such example is in the field of knowledge representation. In his book The Nature of Explanation, Kenneth Craik specified three critical steps for a knowledge-based agent to translate a stimulus into an internal mental model.24 Cognitive processes manipulate this internal model to derive a new model or knowledge representation used to take action. ([Location 602](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=602))
- While we discussed that intelligence is substrate independent, much of modern AI has chosen the computer as its substrate of choice. Computer science provided the field with powerful computing capabilities that make AI applications possible, while work in AI has pioneered many valuable ideas to computer science like time-sharing, windows and mice, linked lists, and object-oriented programming. ([Location 610](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=610))
- Modern linguistics and AI gave rise to a hybrid field called natural language processing, or NLP. NLP deals with the interaction between humans and computers using natural language. ([Location 620](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=620))
- The following are a few reasons for AI to branch out into a separate field: 1. AI is unique in attempting to duplicate mental faculties like creativity, learning, self-improvement, and language use.   2. Unlike other disciplines discussed previously, AI is the only field that attempts to build intelligent machines that function autonomously in complex, uncertain environments.   3. Because of its affinity to computer science, the field is amenable to the scientific process of hypothesis building and experimentation. ([Location 628](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=628))
- In the rules-based approach, the AI is programmed to follow a set of specific instructions. The algorithm tells the computer precisely what steps to take to solve a problem or reach a goal. ([Location 674](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=674))
- Also known as sub-symbolic AI, in this approach, the AI is taught, not programmed. Learning happens by giving the AI a set of examples of what it will encounter in the real world and how to respond. For example, to detect faces from an image, an AI may be shown multiple images of faces in different environments. ([Location 677](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=677))
- Machine learning brings a fundamental change to how we build software products. Instead of programming the system to do a specified action, its creators provide data and nurture it to curate desired outcomes. ML is handy when it is difficult to specify exact rules. ([Location 692](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=692))
- When building modern AI products, the role of creators is to curate lots of examples or data to help the system create a model of what you want it to do. Creators are training the model. The model will not always be perfect. The job of creators then is to give it feedback so that the AI improves over time. ([Location 698](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=698))
- AI needs human-centered design. At one level, AI will require that even more people specialize in digital skills and data science.27 However, building beneficial AI products will require more than science, technology, engineering, and math skills. As we deploy AI in society, disciplines like social sciences, humanities, ethics, economics, psychology, and philosophy will be critical in helping manage and develop beneficial AI. ([Location 714](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=714))
- control problem, which is how to build AI that is beneficial to us. How can we know cases when it is not working in our favor? What tools or techniques can we use to make sure that AI does not harm us? ([Location 720](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=720))
    - Tags: [[blue]] 
- building trust. For AI to be helpful, its users need to trust it. We need to make sure that users of AI can trust its results and make appropriate choices. ([Location 722](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=722))
    - Tags: [[blue]] 
- explainability. Many AI systems are notorious for operating in a black box: the reasons for its suggestions are not known or are difficult to explain. The problem of explainability deals with providing appropriate information or explanations for AI’s results so that its users can make informed judgments. ([Location 726](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=726))
    - Tags: [[blue]] 
- Ethics is a critical ingredient for designing beneficial AI products. Our societies are biased, and many times AI models reflect this underlying bias, harming users or leading to unintended consequences. AI ethics focuses on formulating values, principles, and techniques to guide moral conduct when building or deploying AI. ([Location 729](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=729))
    - Tags: [[blue]] 
- Summary This chapter defined AI and described its foundations and the need for human-centered design when building AI products. Here are some of the important points: 1. There are many definitions of artificial intelligence. This book subscribes to the rational agent view of AI. A rational agent acts to achieve the best outcome or the best-expected outcome when there is uncertainty.   2. Intelligence is a substrate-independent property. It can exist irrespective of the underlying material substrate. Intelligence can be present in biological forms like humans as well as silicon forms like computers.   3. Although modern AI is closely related to computer science, it has its foundations in several disciplines: philosophy, mathematics, economics, neuroscience, psychology, computer engineering, control theory and cybernetics, linguistics, and business.   4. We will mainly discuss AI from the point of view of narrow AI—an ability to do specific tasks extremely well. Discussions around artificial general intelligence (AGI) and superintelligence are beyond the scope of this book.   5. Intelligence is also a generic property, that is, anything can become intelligent.   6. For AI to work, it needs to be beneficial for the people it impacts. We need human-centered design to build beneficial AI products. ([Location 735](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=735))
    - Tags: [[orange]] 
    - Note: Summary of Chapter 1
- In the previous chapter, we subscribed to the rational agent definition of AI. In this chapter, we define rational agents in an environment. We describe how AI works from the lens of input-output mappings, feedback loops, and rewards. Toward the end of the chapter, we discuss the probabilistic nature of AI models. ([Location 810](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=810))
    - Tags: [[orange]] 
    - Note: Intro ch 2!
- The idea of the intelligent or rational agent is a central concept of modern AI.1 An agent is something that acts. A rational agent acts so as to achieve the best outcome or, when there is uncertainty, the best possible outcome.2 We expect intelligent agents like computers to do much more than just react to stimuli—they need to operate autonomously, perceive their environments, adapt to change, create goals, and pursue them. ([Location 819](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=819))
    - Tags: [[pink]] 
- Most real-world environments are complex, and there is insufficient time or computing power available. Therefore, most rational agents hope to achieve the best possible outcome by making the best possible decisions. They operate within what is known as limited rationality. ([Location 825](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=825))
    - Tags: [[pink]] 
- An agent is anything that perceives its environment through sensors and acts on it. The agent does this action through actuators. ([Location 832](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=832))
    - Tags: [[pink]] 
- The design of an agent depends on the type of environment and the nature of the problem. You can also think of an environment as the problem statement and the rational agent as its solution. ([Location 842](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=842))
    - Note: The basic design problem concerning agents like AI
- Most real-world problems like coaching a football team, building a product, or running an organization consist of multiple agents. We can classify the type of environment based on the complexity of the task. ([Location 847](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=847))
- Simple environments are observable, discrete, and deterministic, and their rules are known. Examples of simple environments include puzzles and games. You ([Location 849](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=849))
    - Tags: [[orange]] 
- Machines often exceed human performance on such problems in simple environments. ([Location 854](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=854))
    - Tags: [[orange]] 
- Most real-world environments are complex. Running an organization and teaching astrophysics are hard problems. They have complex, mostly unobservable environments, multiple agents and objects, different types of agents and entities, no specific rules, long timescales, and lots of uncertainty. We have ways of solving parts of complex problems but no general method to solve them completely. In the real world, most complex problems are broken down into simple problems. These simple problems are then tackled individually and sometimes simultaneously. ([Location 855](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=855))
    - Tags: [[orange]] 
- An agent uses sensors to perceive its environment. We use the eyes, ears, nose, and other organs to sense the environment. A robotic vacuum cleaner might use cameras, infrared, and other sensors to navigate a room and its obstacles. A software that corrects grammar might use keystrokes, words, or phrases as sensors within the environment of words and grammar rules. ([Location 860](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=860))
    - Tags: [[orange]] 
- Actuators are anything the agent uses to act on the environment. Our goalkeeper uses hands, legs, and other body parts as actuators to block a football. A self-driving car might use its engine, tires, lights, and other instruments as actuators. ([Location 863](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=863))
    - Tags: [[orange]] 
- Agents act on their environment with a particular objective. The simplest way to communicate an objective is in the form of goals. These goals may be static like winning a chess game or dynamic like finding the best possible route where the definition of best possible may change depending on various factors like the time it takes to reach, cost efficiency, or road conditions. ([Location 866](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=866))
    - Tags: [[orange]] 
- The idea of mapping inputs to outputs is another way of thinking about AI. For example, a rational agent like a robotic vacuum cleaner receives input about dust particles through sensors like cameras, infrared, etc. and acts on it to produce an output of a clean room. ([Location 887](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=887))
    - Tags: [[orange]] 
- You can use this simple idea of mapping input and output to build some very innovative and valuable products. Spam filters can match the input of an email to whether it is spam or not. In factories, we can use images of a product to detect defects. ([Location 895](https://readwise.io/to_kindle?action=open&asin=B0B9JCDZDB&location=895))
    - Tags: [[orange]] 
