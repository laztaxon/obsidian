# Beyond Vector Search: Knowledge Management With Generative AI

![rw-book-cover](https://miro.medium.com/v2/resize:fit:1200/0*aT92XefvMU3jlmsl.png)

## Metadata
- Author: [[David Shapiro]]
- Full Title: Beyond Vector Search: Knowledge Management With Generative AI
- Category: #articles
- Summary: The article discusses the limitations of current AI tools and provides a comprehensive overview of knowledge management strategies and concepts that can help take AI assistants to the next level. The author covers critical ideas like data ontologies, reconciliation, factual grounding, and more, to provide readers with a toolkit to transform a basic chatbot into a sophisticated AI assistant properly integrated into a company's knowledge ecosystem. The article also suggests practical strategies and examples for implementing these principles to create a knowledge-driven AI assistant.
- URL: https://medium.com/@dave-shap/beyond-vector-search-knowledge-management-with-generative-ai-6c2d10b481a0

## Highlights
- ![](https://miro.medium.com/v2/resize:fit:700/0*aT92XefvMU3jlmsl.png)
  Library Science is seriously underrated. You probably should hire a librarian to help you out with AI.
  Introduction
  Many companies today have begun experimenting with conversational AI tools and chatbots that are powered by large language models like GPT-3. At first, these tools seem extremely promising — the AI is able to respond coherently to prompts and appears quite intelligent. However, most teams soon start to encounter severe limitations around the AI’s inability to maintain context, lack of grounding in facts, difficulty integrating into real workflows and business logic, and challenges steering the AI away from unproductive tangents.
  This article aims to provide a comprehensive overview of knowledge management strategies and concepts that can help take AI assistants to the next level. Drawing on extensive professional experience in enterprise IT infrastructure and automation as well as AI consulting, coupled with an understanding of key principles from library and information science, philosophy, and computer science, I will cover critical ideas like data ontologies, reconciliation, factual grounding, and more. The goal is to provide readers with a toolkit to transform a basic chatbot into a sophisticated AI assistant properly integrated into the company’s knowledge ecosystem, avoiding the “sad little lost robot” syndrome many teams currently face.
  The Problem: Limitations of Current AI Tools
  Early experiments using chatbots and other tools powered by large language models often seem to go well at first. The AI is able to respond intelligently to one-off prompts and appears coherent. However, real limitations quickly become apparent during sustained use.
  The AI has no memory or ability to manage conversational context across multiple questions. It lacks any cumulative knowledge. The AI also has no grounding in facts or connection to authoritative sources, so it tends to hallucinate or speculate incorrectly. Another challenge is the difficulty integrating the AI into real business workflows, data sources, and logic. There is no way to smoothly interconnect the AI with other systems. Finally, it is hard to direct the focus of the AI or steer it towards valuable responses and away from unproductive tangents that waste time.
  In essence, while large language models like ChatGPT demonstrate impressive capability, the AI is operating in a vacuum without the knowledge infrastructure required to serve as a truly useful assistant. Building that infrastructure is the focus of the rest of this article.
  The solution? You need Knowledge Management.
  Background
  I come to this topic with over 15 years of experience as an enterprise IT infrastructure engineer focused on areas like automation, cloud computing, and virtualization. I now consult with companies specifically looking to develop and integrate AI technology into their organizations. This experience across the technical spectrum of IT gives me a rather unique perspective on how to approach developing AI assistants. Additionally, I have the benefit of being married to a professional librarian, an expert in organizing and delivering knowledge in ways that end users can easily access.
  My wife has now transitioned to data product owner, so the article that follows is basically dinner table conversation for us.
  How to Use This Article
  In the following sections, I will be covering concepts drawn from diverse disciplines including information science, philosophy, computer science, and more. To get the most value, readers should aim to fully wrap their heads around these ideas, read sections multiple times if needed, look up unfamiliar terms, and synthesize how the concepts can be integrated together into product design, data management, and other aspects of an AI assistant architecture. Having the [slide deck](https://github.com/daveshap/YouTube_Slide_Decks/blob/main/Business%20and%20Product/Knowledge%20Management.pdf) handy as a reference is highly recommended. I’m also happy to help explain concepts in more depth via my Patreon for those who need additional support. Let’s dive in!
  Key ConceptsData Ontologies
  In the realm of databases and philosophy, an ontology refers to the structured framework used to organize and define relationships between different types of data within a domain. “Ontology” basically means “nature of being.” In other words, how does the data exist?
  Data ontologies refer to the structured framework used to organize and define relationships between different types of data within a domain. For example, at a hospital, the data ontology would specify that a “patient” entity has attributes like name, date of birth, address, medical history, current medications, etc. A “doctor” entity would have attributes like name, employee ID, specialty, list of patients. Relationships might include “doctor treats patient” or “patient prescribed medication”. The ontology outlines the hierarchy of broader concepts like “person” versus specific concepts like “patient” or “doctor”. It also encapsulates rules like only allowing integers for fields like age, or ensuring a patient can only have one primary physician. A clear ontology provides meaning and actionability to data that would otherwise just be an abstract structure.
  Understanding data ontologies will help teams properly structure and relate the information that AI assistants require.
  Reconciliation & Validation
  Reconciliation involves ensuring that different sets of data are consistent and accurate when combined or compared, a process often used during data integration or data migration initiatives. Key aspects include:
  Reconciliation involves ensuring that different sets of data are consistent and accurate when combined or compared, a process often used during data integration projects. For example, finance teams regularly reconcile expense reports and credit card statements to ensure the company’s financial records are correct. This involves steps like data matching to align charges on the statement with their matching expense reports, error detection to find any inconsistencies, data cleansing to fix the errors, and validation against the company’s accounting system as the source of truth. The goal is to prevent bad data from propagating through the system. Thorough reconciliation is critical for AI systems as well to prevent them from operating on incorrect or contradictory information that leads to nonsensical outputs.
  Thorough reconciliation is critical for preventing AI assistants from working off of bad data.
  Factual Grounding
  Factual grounding refers to the practice of basing statements, theories, recommendations, and conclusions on verifiable facts and empirical evidence. For example, a financial advisor should ground their investment recommendations in detailed analysis of historical market data, financial filings, and economic indicators rather than speculation or personal opinion. Key elements include relying on quantifiable observed data, confirming validity by cross-referencing multiple reliable sources, ensuring logical consistency, and subjecting findings to expert scrutiny. Factual grounding prevents an AI system from generating fictional or hallucinated content by anchoring its outputs to documented facts and evidence. Just like a human analyst, an AI should cite sources and empirical data to back up any assertions.
  Grounding AI in solid facts rather than speculation is crucial for keeping responses credible and avoiding hallucinated or fictitious output.
  Source of Truth
  A source of truth refers to the authoritative, master data source that is considered the most accurate and reliable for a particular piece of information. Key attributes include:
  A source of truth refers to the authoritative, master data source considered the most accurate and reliable for a particular piece of information. For example, in enterprise IT, the central authentication server acts as the source of truth for user credentials and access controls rather than having this information stored locally across individual servers. This provides consiste ([View Highlight](https://read.readwise.io/read/01heqyw1v6hcteymgcjp7n81r3))
